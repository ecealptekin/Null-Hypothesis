# -*- coding: utf-8 -*-
"""sample_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jeb-xxfl8_9r-mELusDJ519UP_4TdI6F

# CS210 Spring 2019 - Sample Final Project 
# Group No: ...
# NBA Dataset Exploration 

#### Group Members:
- ...
- ...
- ...

![](https://static01.nyt.com/images/2019/03/17/sports/17lakers-knicks-web1/merlin_152236902_5137d65d-45c4-4ef9-ae6f-915a5f104d28-threeByTwoSmallAt2X.jpg)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from datetime import datetime
import seaborn as sns
from datetime import datetime

import warnings
warnings.filterwarnings('ignore')

sns.set(style="darkgrid")

# %matplotlib inline

from os.path import join
from pprint import pprint

d_path = "./data"
d_file = "nba_players.csv"

df = pd.read_csv(join(d_path, d_file))

df.head()

"""# Project Description

In this project, our goal is to display statistical facts in different NBA seasons through self-explanatory visualizations and tables regarding various aspects such as 

- The effect of age on players' performance?
- The relationship between different attributes of a player
- Top performers in different fields
- Individual player statistics

At the end, we aim to perform predictive analysis based on player performances.

# Dataset

We obtained the dataset from [Kaggle](https://www.kaggle.com/drgilermo/nba-players-stats) as raw csv. The dataset includes individual performances of each player from **1950 to 2017** with **52 attributes**. We have **24658 unique players** that are present in the dataset. Most of the attributes are of float data type with the exception of player name, position, team name and year. You may find the related information below.
"""

n_rows, n_columns = df.shape  # get the shape of dataframe
print("number of rows: {}, number of columns: {}".format(n_rows, n_columns))

df["Player"].unique().shape  # getting unique player count

df.dtypes  # data types of each column

"""# Preprocessing

Here, we will first take a look at the NaN values and try come up with different methods to deal with them.  
In addition, we'll check if there exists any column to be added.

### Dealing with NaN values
"""

df.isnull().sum()  # NaN counts in each column

na_ratios = df.isnull().sum() / n_rows  # finding the NaN value ratio of each column
                                        # it returns a series object with column names as indices
na_ratios

"""We can see that columns **"blanl"** and **"blank2"** are completely empty. Let's remove them with `drop` function."""

df.drop(["blanl", "blank2"], axis=1, inplace=True)  # set inplace to True
                                                    # to apply the changes to the dataframe

"""Now, let's check if there are any patterns between NaN rows, starting with ***"Year"** column."""

df[df["Year"].isnull()]

"""It turns out that whenever the **"Year"** row is NaN, the rest of the columns also have NaN. So, we can remove these rows without any concern. In order to remove them, we can extract the index values of these rows and provide it to `drop` function."""

index2drop = df[df["Year"].isnull()].index  # we use the index attribute here
                                            # since, we have a dataframe
df.drop(index2drop, inplace=True)

"""Now, let's check the NaN values one more time. There seems to be a pattern between different attributes. We can use one of these attributes to observe the pattern."""

df.isnull().sum()

"""Now, we can convert ***Year*** column to datetime object."""

# converting float year column to datetime object
df["Year"] = pd.to_datetime(df["Year"].astype(np.int32), format="%Y")

df[df["ORB"].isnull()]

df[df["ORB"].isnull()]["Year"].describe()

"""It seems that **"Year"** column has an effect. Let's apply a filter on **"Year"** column so that we end up with an era in which NBA started to become a global phenomena. The first three-point shot is recorded on [October 12, 1979](http://www.wikizero.biz/index.php?q=aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvVGhyZWUtcG9pbnRfZmllbGRfZ29hbA), that is also the season when the rivalry between Magic Johnson and Larry Bird started."""

df = df[df["Year"] > datetime(1979, 1, 1)]  # filtering on year column

df.isnull().sum()

"""Still, we have NaN values on some columns such as `FT%`, `FG%`, `3P%` and `2P%`. We can fill the NaN values on these columns."""

matchings = {
    "FT%" : {
        "made": "FT",
        "attempted": "FTA"
    },
    "FG%": {
        "made": "FG",
        "attempted": "FGA"
    },
    "3P%": {
        "made": "3P",
        "attempted": "3PA"
    },
    "2P%": {
        "made": "2P",
        "attempted": "2PA"
    }
}

def compute_percentage(row, *args):
    """
    fills NaN values by computing made / attempted
    """
    percentage_attr = args[0]
    
    made = row[matchings[percentage_attr]["made"]]
    attempted = row[matchings[percentage_attr]["attempted"]]
    
    return made / attempted if attempted > 0 else 0  # to prevent zero division

for attr in matchings.keys():  # iterate over columns in which NaNs exist
    df.loc[df[attr].isnull(), [attr]] = df[df[attr].isnull()].apply(compute_percentage, axis=1, args=([attr]))

def compute_3PAr(row):
    """
    computes the share of 3-point shot attemps
    """
    two_points = row["2PA"]
    three_points = row["3PA"]
    total = two_points + three_points
    
    return three_points / total if total > 0 else 0

df.loc[df["3PAr"].isnull(), ["3PAr"]] = df[df["3PAr"].isnull()].apply(compute_3PAr, axis=1)

df.isnull().sum()  # let's leave other NaN values as they are

"""# Data Exploration

Now, let's observe the distributions of specific columns, namely **games played** and **points**.
"""

sns.distplot(df["G"].values, norm_hist=True)  # games played

plt.xlabel("games")
plt.title("Distribution of Games Played")
plt.show()

sns.distplot(df["PTS"], norm_hist=True)  # points

plt.xlabel("points")
plt.title("Distribution of Total Points")
plt.show()

"""Here, we can see that most players completed the season around 80 games. In addition, points distribution seems to obey the power law."""

plt.subplot(3,1,1)
sns.boxplot(data=df[["G"]], orient="h")

plt.subplot(3,1,2)
sns.boxplot(data=df[["PTS"]], orient="h")

plt.subplot(3,1,3)
sns.boxplot(data=df[["3PA"]], orient="h")

plt.tight_layout()  # auto. positioning of subplots
plt.show()

"""With box plots, we are able to observe the outliers in different columns. For example, **games played** has no outliers since we have a balanced distribution; while **points** and **3-point attempts** have many outliers.

We analyse how attributes relate to each other.
"""

cols2plot = ["PTS", "MP"]
sns.pairplot(data=df, vars=cols2plot)

plt.show()

"""As expected, as **minutes played** increases, we see an exponential increase in the **points**."""

cols2plot = ["MP", "PTS", "PF"]

# applying a filter on year
sns.pairplot(data=df[df["Year"] > datetime(2012,1,1)], vars=cols2plot, hue="Pos", markers=".")
plt.show()

"""### Extracting Some Insights"""

top5scorers = df.groupby(by="Player").sum()["PTS"].sort_values(ascending=False)[:5]
print(top5scorers)

top5scorers.plot(kind="barh", color="steelblue")  # does not match with the official list
                                                  # since we removed some of the veterans

plt.xlabel("points")
plt.title("Top 5 Scorers")
plt.show()

"""This is not the official list, since we removed some players when we discarded pre-1980 era.

#### How does age affect points made?
"""

min_age = df["Age"].min()
max_age = df["Age"].max()

age_group = df.groupby(by="Age").sum()  # group by age and take sum of each column
pts_game = age_group["PTS"] / age_group["G"]  # find pts avg. at each age

ax = pts_game.plot(kind="bar",
                   color="steelblue",
                   rot=70)

for tick in ax.xaxis.get_major_ticks()[::2]:  # just to make it more readable
    tick.label1.set_visible(False)            # hiding some xticks

plt.ylabel("Avg. Points")
plt.title("Age vs Points")
plt.show()

"""Again, as expected, as **age** increases, we observe a dramatic change for the **points**.

#### Stephen Curry Shot Selection in Each Season
"""

df["2PAr"] = 1 - df["3PAr"]  # adding the two point shot rate column

player = "Stephen Curry"
player_df = df[df["Player"] == player]

player_df.set_index(player_df["Year"].dt.strftime("%Y"), inplace=True)  # change index to display
                                                                        # years as xticks

player_df[["2PAr", "3PAr"]].plot.bar(rot=60)
plt.title("Shot Selection in Each Season by {}".format(player))
plt.show()

"""He just likes to shoot the ball from the distance.

# Hypothesis Testing

#### How did Golden State Warriors affect the league?

There is an ongoing debate regarding the shot selections in NBA. Teams strated to focus more on three points shots and changed their game plans accordingly. Some of the experts credit Golden State Warriors as the initiater team, beacuse of players like Curry and Thompson. You can learn more about the discussion from this [link.](https://www.pinnacle.com/en/betting-articles/Basketball/three-point-shots-nba/VPN2MLSADYW5FPZL)

Let's check if we can see such a phenomena in our dataset.
"""

base_year = 1990
gw_year = 2012

# checking 3-point shot attemps 
past_df = df[(df["Year"] < datetime(2012, 1, 1)) & (df["Year"] >= datetime(2007, 1, 1))]
gs_df = df[df["Year"] > datetime(2012, 1, 1)]

ax = sns.kdeplot(past_df["3PAr"].rename("2007-2012"), shade=True)
sns.kdeplot(gs_df["3PAr"].rename("2012-2017"), ax=ax, shade=True)

plt.show()

"""The difference between two terms is visible. Now, let's apply a significance test to statistically approve this difference. Here, we created two different samples, before and after 2012. Since we have two samples, we simply decided to apply two-sample t-test to show that two eras are different in terms of 3-point shot attempts. Below, you may find the hypothesis statements.

$H_0 \rightarrow \mu_{pre-2012-3PAr} = \mu_{post-2012-3PAr}$  
$H_A \rightarrow \mu_{pre-2012-3PAr} \neq \mu_{post-2012-3PAr}$
"""

# extracting values
past_values = past_df["3PAr"].values
gs_era = gs_df["3PAr"].values

# two-sided test for the null hypothesis that 2 independent samples 
# have identical average (expected) values
_, p_value = stats.ttest_ind(a=past_values, b=gs_era, equal_var=False)
p_value

"""We set the significance level as 0.05 as general.  
Based on the value of obtained p_value, we can **reject** the null hypothesis.
"""

